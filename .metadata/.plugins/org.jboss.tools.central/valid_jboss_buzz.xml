<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title type="html">WildFly 29 is released!</title><link rel="alternate" href="https://wildfly.org//news/2023/07/21/WildFly29-Released/" /><author><name>Brian Stansberry</name></author><id>https://wildfly.org//news/2023/07/21/WildFly29-Released/</id><updated>2023-07-21T00:00:00Z</updated><content type="html">I’m pleased to announce that the new WildFly and WildFly Preview 29.0.0.Final releases are available for download at . NEW AND NOTABLE During the WildFly 29 development cycle the WildFly contributors were heavily focused on bug fixing, plus a lot internal housekeeping that needed doing after all the recent work toward Jakarta EE 10. But we do have some new goodies: * It is now possible to . * You can use Galleon to using the new Keycloak SAML Adapter feature pack. * You can use Galleon to using the 1.0.0.Beta1 release of the new . (Note that the feature pack is still a Beta.) * The elytron subsystem’s new Distributed Realm attribute ignore-unavailable-realms enables a user to . SUPPORTED SPECIFICATIONS JAKARTA EE WildFly 29 is a compatible implementation of the EE 10 as well as the and the . WildFly is EE 10 compatible when running on both Java SE 11 and Java SE 17. Evidence supporting our certification is available in the repository on GitHub: Specification Compatibility Evidence Jakarta EE 10 Full Platform Jakarta EE 10 Web Profile Jakarta EE 10 Core Profile MICROPROFILE WildFly supports numerous MicroProfile specifications. Because we no longer support MicroProfile Metrics, WildFly 28 cannot claim to be a compatible implementation of the MicroProfile 6.0 specification. However, WildFly’s MicroProfile support includes implementations of the following specifications in our "full" (e.g. standalone-full.xml) and "default" (e.g standalone.xml) configurations as well as our "microprofile" configurations (e.g. standalone-microprofile.xml): MicroProfile Technology WildFly Full/Default Configurations WildFly MicroProfile Configuration MicroProfile Config 3.0 X X MicroProfile Fault Tolerance 4.0  —  X MicroProfile Health 4.0  —  X MicroProfile JWT Authentication 2.1 X X MicroProfile LRA 2.0  —  X MicroProfile OpenAPI 3.1  —  X MicroProfile Open Telemetry 1.0  —  X MicroProfile Reactive Messaging 3.0  —   —  MicroProfile Reactive Streams Operators 3.0  —   —  MicroProfile Rest Client 3.0 X X for the above specifications that are part of MicroProfile 6.0 can be found in the WildFly Certifications repository on GitHub. JAVA SE SUPPORT Our recommendation is that you run WildFly on the most recent long-term support Java SE release, i.e. on SE 17 for WildFly 29. While we do do some testing of WildFly on JDK 20, we do considerably more testing of WildFly itself on the LTS JDKs, and we make no attempt to ensure the projects producing the various libraries we integrate are testing their libraries on anything other than JDK 11 or 17. WildFly 29 also is heavily tested and runs well on Java 11. We anticipate continuing to support Java 11 at least through WildFly 30, and perhaps beyond. We do, however, anticipate removing support for SE 11 sometime in the next 12 to 18 months. While we recommend using an LTS JDK release, I do believe WildFly runs well on JDK 20. By runs well, I mean the main WildFly testsuite runs with no more than a few failures in areas not expected to be commonly used. We want developers who are trying to evaluate what a newer JVM means for their applications to be able to look to WildFly as a useful development platform. Please note that WildFly runs in classpath mode. MIGRATION ISSUES In this section of these release announcements I’ll note issues users may experience when migrating from a previous version of WildFly. GALLEON TOOLING We’ve added additional metadata to the files provide to the Galleon tooling, with the aim of providing exciting new provisioning capabilities. (Keep an eye out for more on those new capabilities in a future WildFly release.) This addition, however necessitates that in order to provision WildFly 29 users must update the versions of Galleon-related tooling they use. * For those who use the to provision WildFly, or later is required. * or later is also required for users of the * For those who use the to provision WildFly, or later is required. * For users who use the to produce a bootable jar: or later is required. We are working to add improved forward compatibility to our tooling to help reduce the likelihood that future improvements will require users to update their tooling versions in order to work with newer releases of WildFly. RELEASE NOTES The full release notes for the release are in the . Issues fixed in the underlying release are listed in the WildFly Core JIRA. Please try it out and give us your feedback, in the , or . Meanwhile, we’re busy at work on WildFly 30! Best regards, Brian</content><dc:creator>Brian Stansberry</dc:creator></entry><entry><title>How to balance per-CPU upcall dispatch mode in Open vSwitch</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/20/how-balance-cpu-upcall-dispatch-mode-open-vswitch" /><author><name>Michael Santana</name></author><id>8cdce30c-414d-4d73-b63f-953d4924da75</id><updated>2023-07-20T07:00:00Z</updated><published>2023-07-20T07:00:00Z</published><summary type="html">&lt;p&gt;Open vSwitch has moved away from using per-vport dispatch mode to using per-CPU dispatch mode. But this mode had issues with upcall handler thread imbalance and CPU mismatch error messages. These issues were mostly found in systems with tuned CPUs.&lt;/p&gt; &lt;p&gt;This article explains two main fixes that my patch series applied to Open vSwitch that alleviated these issues. The first fix resulted in the ovs-vswitchd sending an array of a size that the Open vSwitch kernel module will accept and not trigger the CPU mismatch error message. The second fix added additional upcall handler threads in cases of tuned CPUs to create a more balanced workload for the upcall handler threads.&lt;/p&gt; &lt;h2&gt;History of dispatch modes in Open vSwitch&lt;/h2&gt; &lt;p&gt;In July 2021, my former colleague, Mark Grey, &lt;a href="https://github.com/openvswitch/ovs/commit/b1e517bd2f818fc7c0cd43ee0b67db4274e6b972" target="_blank"&gt;introduced per-CPU dispatch mode to Open vSwitch&lt;/a&gt;. This dispatch mode was made to fix issues found in the old &lt;code&gt;per-vport&lt;/code&gt; dispatch mode. In Open vSwitch, the &lt;code&gt;per-vport&lt;/code&gt; dispatch mode creates a netlink socket for each vport. The introduction of &lt;code&gt;per-CPU&lt;/code&gt; dispatch mode fixed a number of issues found in &lt;code&gt;per-vport&lt;/code&gt; mode including &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1844576" target="_blank"&gt;packet reordering&lt;/a&gt; and &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1834444" target="_blank"&gt;thundering herd&lt;/a&gt; issues.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;per-CPU&lt;/code&gt; dispatch mode differs from &lt;code&gt;per-vport&lt;/code&gt; mode in that the number of netlink sockets created in the &lt;code&gt;per-CPU&lt;/code&gt; dispatch mode is equal to the number of upcall handler threads created. And most importantly, each netlink socket maps to exactly one upcall handler thread. The idea behind &lt;code&gt;per-CPU&lt;/code&gt; dispatch mode is to have a one-to-one correspondence between CPU, netlink socket, and upcall handler thread, as shown in the diagram in Figure 1. This idea fixed the old issues in &lt;code&gt;per-vport&lt;/code&gt; mode.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/handlers_one_to_one_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/handlers_one_to_one_0.png?itok=-_NQtHmx" width="600" height="257" alt="A diagram showing handlers one-to-one mapping between the CPU, netlink socket, and handler thread." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The handlers one-to-one mapping between the CPU, netlink socket, and handler thread.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;A user can determine which mode their system is running via the following command: &lt;code&gt;ovs-appctl dpif-netlink/dispatch-mode&lt;/code&gt;. The dispatch mode defaults to per-CPU when using a kernel &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1834444#c12" target="_blank"&gt;at least &lt;/a&gt;&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1834444#c12" target="_blank"&gt;&lt;code&gt;4.18.0-328.el8.mr1064_210805_1629&lt;/code&gt;&lt;/a&gt; and cannot be changed by the user.&lt;/p&gt; &lt;p&gt;One intentional side effect of the &lt;code&gt;per-CPU&lt;/code&gt; dispatch mode is that now users &lt;strong&gt;cannot&lt;/strong&gt; change the number of upcall handler threads via the user-configurable variable &lt;code&gt;n-handler-threads&lt;/code&gt; in &lt;code&gt;per-CPU&lt;/code&gt; dispatch mode. The user-configurable variable &lt;code&gt;n-handler-threads&lt;/code&gt; only works in &lt;code&gt;per-vport&lt;/code&gt; dispatch mode.&lt;code&gt; &lt;/code&gt;In &lt;code&gt;per-CPU&lt;/code&gt; dispatch mode, the number of upcall handler threads is determined by the number CPUs in which &lt;code&gt;ovs-vswitchd&lt;/code&gt; can run on, which is largely affected by the affinity of &lt;code&gt;ovs-vswitchd&lt;/code&gt; or the number of tuned CPUs via CPU isolation.&lt;/p&gt; &lt;p&gt;After merging the &lt;code&gt;per-CPU&lt;/code&gt; dispatch mode, there were bugs (&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=2102449" target="_blank"&gt;BZ#2102449&lt;/a&gt;, &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=2006605" target="_blank"&gt;BZ#2006605&lt;/a&gt;), reporting that Open vSwitch kernel module threw the following error message: &lt;code&gt;openvswitch: cpu_id mismatch with handler threads&lt;/code&gt;. These CPU mismatch error messages typically happened on systems with tuned CPUs or disabled cores.&lt;/p&gt; &lt;h2&gt;What caused the problem?&lt;/h2&gt; &lt;p&gt;The CPU mismatch error message originates from the fact that the Openvswitch Kernel Module expects an array with a size equal to the number of CPUs in the system as shown in the following code snippet in the Linux kernel &lt;code&gt;net/openvswitch/datapath.c&lt;/code&gt; where &lt;code&gt;handlers_array_size&lt;/code&gt; is the size of &lt;code&gt;handlers_array&lt;/code&gt; and &lt;code&gt;cpu_id&lt;/code&gt; is the CPU in which the upcall happened on the system.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-c"&gt;if (handlers_array_size &gt; 0 &amp;&amp; cpu_id &gt;= handlers_array_size) { pr_info_ratelimited("cpu_id mismatch with handler threads"); return handlers_array[cpu_id % handlers_array_size]; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Each index of the &lt;code&gt;handlers_array&lt;/code&gt; corresponds to the CPU ID on which an upcall can occur and each element in the array is a netlink socket file descriptor corresponding to an upcall handler thread. The array maps upcalls that happen on a particular CPU to a corresponding upcall handler thread via the contained netlink socket file descriptor in the array. The array determines which upcall handler thread will receive the upcall.&lt;/p&gt; &lt;p&gt;The problem is that &lt;code&gt;ovs-vswitchd&lt;/code&gt; was not sending an array of the expected size, and it was not sending a mapping for all CPUs. Instead, it was sending an array with a size equal to the number of upcall handler threads. As mentioned earlier, the default behavior in &lt;code&gt;ovs-vswitchd&lt;/code&gt; is to create as many upcall handler threads as there are available CPUs for &lt;code&gt;ovs-vswitchd&lt;/code&gt; to run on. This is not a problem when the CPU affinity of &lt;code&gt;ovs-vswitchd&lt;/code&gt; is not set.&lt;/p&gt; &lt;p&gt;However, it is a problem when the CPUs are tuned or disabled, or the affinity of &lt;code&gt;ovs-vswitchd&lt;/code&gt; is changed. The default behavior is to create as many upcall handler threads as there are available CPUs for &lt;code&gt;ovs-vswitchd&lt;/code&gt; to run on, but if we have tuned or disabled CPUs the number of upcall handler threads will be &lt;em&gt;l&lt;/em&gt;ess than the total number of CPUs. We would hit the condition &lt;code&gt;cpu_id &gt;= handlers_array_size&lt;/code&gt; when the system receives an upcall on a CPU ID that is larger or equal than &lt;code&gt;handlers_array_size&lt;/code&gt; causing the CPU mismatch error message (Figure 2).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/handlers_without_fix.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/handlers_without_fix.png?itok=Z998Pizw" width="600" height="251" alt="A diagram of the handlers without the fix." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: The handlers without the fix is in imbalance.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;The CPU mismatch impact&lt;/h2&gt; &lt;p&gt;The most visible impact is the CPU mismatch error message. But there are other more severe issues that can occur. One of them is overloading upcall handler threads while simultaneously starving others in the case of fixed Receive Packet Steering (RPS), powered off CPUs, or unplugged CPUs, which will be discussed later. This can happen as a side effect of the Open vSwitch kernel module using a modulo operation (shown in the previous code snippet) on the array when there is a CPU mismatch. In essence, some upcall handler threads get all the workload, while others are always on standby. This is an obvious misuse of CPU utilization.&lt;/p&gt; &lt;p&gt;There is also an issue of not having enough upcall handler threads to service the upcalls. Isolated CPU cores can still receive packets even if the core is isolated, and can still trigger an upcall. We still need upcall handler threads to service upcalls triggered by isolated CPUs. We cannot just create as many upcall handler threads as there are non-isolated CPUs because we would underperform in cases with high upcall usage across non-isolated and isolated CPUs. So we should ideally increase the number of upcall handler threads in CPU isolation cases to create a more balanced workload.&lt;/p&gt; &lt;p&gt;Figure 2 shows a system configured with four active CPUs for &lt;code&gt;ovs-vswitchd&lt;/code&gt; to use, but it only created four upcall handler threads. Two of these upcall handler threads (H0, H1) have to service three CPUs each while the other two upcall handler threads (H2, H3) only have to service two CPUs.&lt;/p&gt; &lt;h2&gt;2 Solutions to improve CPU performance&lt;/h2&gt; &lt;p&gt;The fix is two-fold. First, create an array that’s big enough to not trigger the CPU mismatch error message. How we go about deciding how big to create the array is not as straightforward as one would think. Count the total number of CPUs regardless of if they are active or not. That would work, but not on all systems. Some systems have noncontinuous CPU Core IDs. For example, the largest CPU core ID in a particular system is CPU9, but this system only has four CPUs (Figure 3).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/handlers_with_fix_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/handlers_with_fix_0.png?itok=6_eiBY0z" width="600" height="257" alt="A diagram of Open vSwitch handlers with the fix." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: The handlers with the fix.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If &lt;code&gt;ovs-vswitchd&lt;/code&gt; sent an array of size 4 to the Open vSwitch kernel module and the system gets an upcall on CPU9, it would still throw a CPU mismatch error message, as previously explained.&lt;/p&gt; &lt;p&gt;Instead, &lt;code&gt;ovs-vswitchd&lt;/code&gt; sends the OVS kernel module an array of size:&lt;/p&gt; &lt;p&gt;&lt;code&gt;size = MAX(count_total_cores(), largest_cpu_id + 1)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;The &lt;code&gt;count_total_cores&lt;/code&gt; would be the total number of CPUs, and &lt;code&gt;largest_cpu_id&lt;/code&gt; is the largest CPU in the system. In the previous example, this would be size 4 and CPU9 (don’t forget to add +1) respectively, then pick the largest of the two numbers. This guarantees that the &lt;code&gt;ovs-vswitchd&lt;/code&gt; sends the size the Open vSwitch kernel module expects. This prevents the CPU mismatch error message. The reason this works is because the Openvswitch Kernel Module side gets the upcall from CPU9 and checks to see if CPU9 is less than the array size 10 the &lt;code&gt;ovs-vswitchd&lt;/code&gt; sent. Since 9 is less than 10, we do not trigger the mismatch. If &lt;code&gt;ovs-vswitchd&lt;/code&gt; had sent an array of size 4, we would have triggered a CPU mismatch. This is the complete fix.&lt;/p&gt; &lt;p&gt;Secondly, we decided to go one step forward and try to create a more fair distribution of upcalls amongst the upcall handler threads by increasing the number of upcall handler threads. An upcall can happen on any CPU, even on CPUs that are isolated. Normally, &lt;code&gt;ovs-vswitchd&lt;/code&gt; does not have isolated CPUs. In this case, &lt;code&gt;ovs-vswitchd&lt;/code&gt; creates as many upcall handler threads as there are CPUs.&lt;/p&gt; &lt;p&gt;But in the case that we have isolated CPUs &lt;code&gt;ovs-vswitchd&lt;/code&gt; would normally create as many upcall handler threads as there are non-isolated CPUs. This can be an issue because &lt;code&gt;ovs-vswitchd&lt;/code&gt; still need upcall handler threads to service the upcalls that happen on isolated CPUs.&lt;/p&gt; &lt;p&gt;This is where the additional upcall handler threads come in. Having additional upcall handler threads provides the system with a more fair distribution of upcall workload amongst isolated and non-isolated CPUs. This also improves the imbalance of overloading some upcall handler threads that are found in fixed Receive Packet Steering (RPS), powered off CPUs, or unplugged CPUs. But it does not completely fix it. It helps because the more threads, the more the likely that each actually active CPU gets a unique upcall handler thread and reduces the amount of workload per thread.&lt;/p&gt; &lt;p&gt;The formula for deciding the number of upcall handler threads is as follows:&lt;/p&gt; &lt;p&gt;&lt;code&gt;handlers_n = min(next_prime(active_cores+1), total_cores)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Where &lt;code&gt;next_prime(argument)&lt;/code&gt; is a function that returns the &lt;code&gt;argument&lt;/code&gt; if &lt;code&gt;argument&lt;/code&gt; is a prime number or the next prime after &lt;code&gt;argument&lt;/code&gt;. This guarantees that &lt;code&gt;ovs-vswitchd&lt;/code&gt; has additional upcall handler threads in the case that the system has CPU isolation, but not exceed the maximum number of CPUs. The &lt;code&gt;ovs-vswitchd&lt;/code&gt; fills in the array in a round-robin fashion where &lt;code&gt;ovs-vswitchd&lt;/code&gt; rotates the upcall handler threads. &lt;code&gt;ovs-vswitchd&lt;/code&gt; also uses the modulo operator to restart counting from the first upcall handler thread.&lt;/p&gt; &lt;p&gt;I took all the above suggestions and got &lt;a href="https://github.com/openvswitch/ovs/commit/2803b3fb53f11cc6398294b9b6c365f53d50e0d3"&gt;a patch series merged into Open vSwitch upstream that fixes the Upcall Handler Thread mapping&lt;/a&gt;. In Figure 3, we have a system with my patch series applied with ten CPUs, but only four of them are actually available for &lt;code&gt;ovs-vswitchd&lt;/code&gt; to use. In this example, &lt;code&gt;ovs-vswitchd&lt;/code&gt; creates five upcall handler threads based on the previous equation when using &lt;code&gt;active_cores = 4, total_cores = 10&lt;/code&gt;. Also, each upcall handler threads get the same number of CPUs they need to service.&lt;/p&gt; &lt;h2&gt;Caveats&lt;/h2&gt; &lt;p&gt;This implementation is not a perfect solution. There are many edge cases that this implementation does not address. But we have found that this implementation is the most balanced solution. A better implementation might dynamically change which handlers serve which CPUs according to the RPS scheme used by the NIC for the most optimized performance, but that comes at additional computational overhead.&lt;/p&gt; &lt;p&gt;This implementation is not aware of which CPUs are non-existent or plugged in, which means that there could be cases where you could overload handlers while starving others. This is true in cases of non-existing CPUs or hot-swappable CPUs.&lt;/p&gt; &lt;h2&gt;Related works&lt;/h2&gt; &lt;p&gt;My colleague, Adrián Moreno Zapata, built on top of my work and got a &lt;a href="https://github.com/openvswitch/ovs/commit/0d23948a598ac609e9865174e0874e782a48d6a8" target="_blank"&gt;patch series merged&lt;/a&gt; that allows for a dynamic number of upcall handler threads when the number of CPUs change during ovs-vswitchd run time. The number of CPUs can change for many reasons during run time, including CPUs being hot-plugged, switched on or off, or affinity mask of ovs-vswitchd changing. Another colleague, &lt;a href="https://developers.redhat.com/author/echaudron"&gt;Eelco Chaudron&lt;/a&gt; took a deep dive into the world of &lt;a href="https://developers.redhat.com/articles/2022/10/19/open-vswitch-revalidator-process-explained" target="_blank"&gt;revalidator threads&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/20/how-balance-cpu-upcall-dispatch-mode-open-vswitch" title="How to balance per-CPU upcall dispatch mode in Open vSwitch"&gt;How to balance per-CPU upcall dispatch mode in Open vSwitch&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Michael Santana</dc:creator><dc:date>2023-07-20T07:00:00Z</dc:date></entry><entry><title>Quarkus 3.2.1.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-3-2-1-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-3-2-1-final-released/</id><updated>2023-07-20T00:00:00Z</updated><published>2023-07-20T00:00:00Z</published><summary type="html">Today, we released Quarkus 3.2.1.Final, the first maintenance release of our 3.2 release train. As usual, it contains bugfixes and documentation improvements. It should be a safe upgrade for anyone already using 3.1, but if you are using OpenAPI and/or Swagger UI, please have look below. If you are not...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2023-07-20T00:00:00Z</dc:date></entry><entry><title>How to retrieve packet drop reasons in the Linux kernel</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/19/how-retrieve-packet-drop-reasons-linux-kernel" /><author><name>Antoine Tenart</name></author><id>c81250ec-0fca-472f-9d40-943ba5153745</id><updated>2023-07-19T07:00:00Z</updated><published>2023-07-19T07:00:00Z</published><summary type="html">&lt;p&gt;Understanding why a packet drops in the Linux kernel is not always easy. The networking stack is wide and reasons to refuse a given packet are multiple and include invalid data from a protocol, firewall rules, wrong checksum, full queues, qdisc or XDP actions, and many more reasons. It is possible to look at indicators such as MIB counters and statistic counters, but often those are generic and triggered for different reasons, but most importantly their coverage is small, and it's impossible to match a specific packet to a given counter increase. &lt;/p&gt; &lt;h2&gt;Socket buffer drop reasons&lt;/h2&gt; &lt;p&gt;The socket buffer, SKB (&lt;code&gt;struct sk_buff&lt;/code&gt;) is the main data structure representing a packet in the Linux kernel networking stack. When a packet is dropped in the Linux kernel, in most cases, it means its associated socket buffer has dropped. In recent versions of the Linux kernel, starting in v5.17, socket buffers can be dropped with an associated reason. This was introduced in upstream commit &lt;a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=c504e5c2f9648a1e5c2be01e8c3f59d394192bd3"&gt;c504e5c2f964 ("net: skb: introduce kfree_skb_reason()")&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Using this commit and later additions, kernel developers are now able to specify why a given packet dropped. In the following example, a packet is dropped because no socket was found:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-diff"&gt;- kfree_skb(skb); + kfree_skb_reason(skb, SKB_DROP_REASON_NO_SOCKET);&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Using tools to retrieve drop reasons&lt;/h2&gt; &lt;p&gt;The SKB drop reason can be retrieved in a few different ways, depending on which you are comfortable using, what is available on a given system, and the end goal (some solutions have more flexibility than others).&lt;/p&gt; &lt;p&gt;The main interface to retrieve the drop reason is the &lt;code&gt;skb:kfree_skb&lt;/code&gt; tracepoint. It provides a user readable text for all drop reasons. A good way to attach to this tracepoint is to use &lt;code&gt;perf&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;# perf record -e skb:kfree_skb curl https://localhost # given no server listens on localhost:443/tcp. # perf script curl 883 [001] 340.799805: skb:kfree_skb: skbaddr=0xffff88811f6a7068 protocol=2048 location=tcp_v4_rcv+0x157 reason: NO_SOCKET curl 883 [001] 340.800860: skb:kfree_skb: skbaddr=0xffff88811f6a6de8 protocol=34525 location=tcp_v6_rcv+0x137 reason: NO_SOCKET&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can see why the two packets where dropped in &lt;code&gt;tcp_v4_rcv&lt;/code&gt; and &lt;code&gt;tcp_v6_rcv&lt;/code&gt; because no socket was found and we do not have a server listening on &lt;code&gt;localhost:443/tcp&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;We can also use other tools such as &lt;code&gt;bpftrace&lt;/code&gt; to get the drop reason, which would give us more flexibility, the drawback being the reason isn't converted to a human readable string:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;# bpftrace -e 'tracepoint:skb:kfree_skb {printf("%s: %d\n", comm, args-&gt;reason)}' -c 'curl https://localhost' Attaching 1 probe... curl: 3 curl: 3 curl: (7) Failed to connect to localhost port 443 after 2 ms: Couldn't connect to server&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Another method is the &lt;code&gt;dropwatch&lt;/code&gt;, an interactive tool to monitor packets dropped in the Linux kernel. When using the &lt;code&gt;packet alert mode&lt;/code&gt;, drop reasons are included.&lt;/p&gt; &lt;pre&gt; &lt;code&gt;# dropwatch -l kas Initializing kallsyms db dropwatch&gt; set alertmode packet Setting alert mode Alert mode successfully set dropwatch&gt; start Enabling monitoring... Kernel monitoring activated. Issue Ctrl-C to stop monitoring drop at: tcp_v4_rcv+0x157/0x1630 (0xffffffff8abc4f87) origin: software input port ifindex: 1 timestamp: Thu Feb 23 18:03:36 2023 370138884 nsec protocol: 0x800 length: 74 original length: 74 drop reason: NO_SOCKET drop at: tcp_v6_rcv+0x137/0x14f0 (0xffffffff8ad91b37) origin: software input port ifindex: 1 timestamp: Thu Feb 23 18:03:36 2023 372335338 nsec protocol: 0x86dd length: 94 original length: 94 drop reason: NO_SOCKET&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;The &lt;a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/net/dropreason-core.h?h=v6.4-rc1#n88"&gt;&lt;code&gt;skb_drop_reason enum&lt;/code&gt;&lt;/a&gt; defines core drop reasons. It is an internal definition, and the actual value of all its members is not guaranteed to be constant over time. This feature is recent and some of the drop reasons were reordered during development. There is also work ongoing for supporting drop reasons from different subsystems. You should either use tools directly providing the drop reason in a text format (perf or dropwatch) or take the right drop reasons definition as a reference when retrieving the drop reason in a numeric way (bpftrace).&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;Not all drop places in the Linux kernel are covered. Converting them to this new facility takes time and resources. There is progress upstream with more additions. Currently, more than &lt;a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/net/dropreason.h?h=v6.2#n81"&gt;70 reasons are supported&lt;/a&gt;. There is also an effort to support more than the core networking subsystem.&lt;/p&gt; &lt;p&gt;SKB drop reasons are now available in &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux&lt;/a&gt; starting with RHEL 8.8 and RHEL 9.2.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/19/how-retrieve-packet-drop-reasons-linux-kernel" title="How to retrieve packet drop reasons in the Linux kernel"&gt;How to retrieve packet drop reasons in the Linux kernel&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Antoine Tenart</dc:creator><dc:date>2023-07-19T07:00:00Z</dc:date></entry><entry><title type="html">Top 20 Must-Read Software Trends Reports for 2023</title><link rel="alternate" href="http://www.ofbizian.com/2023/07/top-20-must-read-software-reports.html" /><author><name>Unknown</name></author><id>http://www.ofbizian.com/2023/07/top-20-must-read-software-reports.html</id><updated>2023-07-18T23:23:00Z</updated><content type="html">In the rapidly evolving software industry, keeping up with new trends, tools, and best practices can be time-consuming. With so much information available, where do you start, and what sources can you trust? I've curated a list of reports that I follow to stay informed and ahead of the curve. These provide insights into everything from programming languages to DevOps, cloud strategy, and security. If you're interested in the latest trends and fascinating posts I come across,  or check out my latest writing on industry trends over at the . I share anything I find insightful and worth reading in the world of cloud and distributed systems.  Here are the top 20 reports for 2023 I came across so far: ReportPublisherTIOBERedMonkStack OverflowInfoQInfoQPostmanDataDogThoughtworksO'ReillyHashiCorpRed HatPuppetLabsVmwareDenoAirByteDatabricksGithubRapidAPICNCFGoogle While these reports offer valuable insights, it's important to keep in mind that they can be opinionated. The key to effectively leveraging these resources lies in cross-verifying trends from multiple sources and using them only as a guide for direction rather than absolute truths. Are there any reports that should be on this list? Tag me on Twitter and I'll include them, subject to my checks I'm always keen to explore new sources! Found this list helpful? Go ahead, Call to action: Are you a user? Your experience is valuable! Contribute your insights and shape the</content><dc:creator>Unknown</dc:creator></entry><entry><title>How to run a custom server task in Red Hat Data Grid</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/18/how-run-custom-server-task-red-hat-data-grid" /><author><name>Torbjorn Dahlen</name></author><id>d88d032d-2289-48ea-a518-eea26fcb73be</id><updated>2023-07-18T07:00:00Z</updated><published>2023-07-18T07:00:00Z</published><summary type="html">&lt;p&gt;Custom server tasks can be deployed to the &lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/data-grid"&gt;Red Hat Data Grid&lt;/a&gt; server for remote execution from the command line interface (CLI) and Hot Rod or REST clients. Tasks can be implemented as custom Java classes or as scripts in languages such as JavaScript.&lt;/p&gt; &lt;p&gt;In this article, we will deploy a Java class that will evict and reload the cache in order to pick up modified entries in the original database table from which we loaded the cache. Data Grid will automatically load new entries added to the database table, however modified rows will require reloading using a server task, as shown in the following example.&lt;/p&gt; &lt;h2&gt;How to deploy PostgreSQL with a custom image&lt;/h2&gt; &lt;p&gt;SQL cache stores let you load Red Hat Data Grid caches from existing database tables. Data Grid offers two types of SQL cache stores: table and query. In the following example, Data Grid will load entries from a single database table. It is also possible to use SQL queries to load entries from single or multiple database tables.&lt;/p&gt; &lt;p&gt;For more details, refer to &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.4/html/configuring_data_grid_caches/persistence#sql-cache-store_persistence"&gt;SQL cache stores&lt;/a&gt;. All source code for this tutorial can be found on &lt;a href="https://github.com/torbjorndahlen/infinispan-evict-cache"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;We will use PostgreSQL to contain the table that will be loaded by Data Grid. To deploy PostgreSQL in &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;, we will use a modified image that initializes the database with a table and a Data Grid user with granted privileges to read from the table.&lt;/p&gt; &lt;pre&gt; FROM registry.redhat.io/rhel8/postgresql-12 LABEL description="This is a custom PostgreSQL container image which loads the database schema definitions and the data into the model and inventory tables " COPY db/load_db.sh /opt/app-root/src/postgresql-start/ COPY db/rpi-store-ddl.sql /opt/app-root/src/postgresql-start/ COPY db/rpi-store-dml.sql /opt/app-root/src/postgresql-start/ COPY db/rpi-store-role.sql /opt/app-root/src/postgresql-start/ USER root RUN chmod 774 /opt/app-root/src/postgresql-start/*.sh USER 26&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;load_db.sh&lt;/code&gt; script populates the table used to load the Data Grid cache and creates the user &lt;code&gt;infinispan&lt;/code&gt; with privileges to &lt;code&gt;SELECT&lt;/code&gt; from the &lt;code&gt;model&lt;/code&gt; table:&lt;/p&gt; &lt;pre&gt; #!/bin/bash START_DIR="$APP_DATA/src/postgresql-start" run_sql_script () { SQL_FILE=$1 psql -U postgres \ --echo-all \ -f $SQL_FILE \ -d $POSTGRESQL_DATABASE } run_sql_script $START_DIR/rpi-store-ddl.sql run_sql_script $START_DIR/rpi-store-dml.sql run_sql_script $START_DIR/rpi-store-role.sql&lt;/pre&gt; &lt;p&gt;Note that the user needs to be &lt;code&gt;postgres&lt;/code&gt; to create a new user.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;rpi-store-ddl.sql&lt;/code&gt; script will run the following SQL commands to create the &lt;code&gt;model&lt;/code&gt; table which will be used to load keys and values into the Data Grid cache:&lt;/p&gt; &lt;pre&gt; drop table if exists model; create table model ( id integer primary key, name varchar(20), model varchar(20), soc varchar(20), memory_mb integer, ethernet boolean, release_year integer );&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;rpi-store-dml.sql&lt;/code&gt;script will create three rows in the &lt;code&gt;model&lt;/code&gt; table:&lt;/p&gt; &lt;pre&gt; insert into model (id, name, model, soc, memory_mb, ethernet, release_year) values (1, 'Raspberry Pi', 'B', 'BCM2835', 256, TRUE, 2012); insert into model (id, name, model, soc, memory_mb, ethernet, release_year) values (2, 'Raspberry Pi Zero', 'Zero', 'BCM2835', 512, FALSE, 2015); insert into model (id, name, model, soc, memory_mb, ethernet, release_year) values (3, 'Raspberry Pi Zero', '2W', 'BCM2835', 512, FALSE, 2021);&lt;/pre&gt; &lt;p&gt;Finally, the &lt;code&gt;rpi-store-role.sql&lt;/code&gt; script will create the user &lt;code&gt;infinispan&lt;/code&gt; and grant &lt;code&gt;SELECT&lt;/code&gt; privileges on the &lt;code&gt;model&lt;/code&gt; table. This user will be provided to the JDBC connector used by Data Grid.&lt;/p&gt; &lt;pre&gt; CREATE USER infinispan WITH PASSWORD 'secret'; GRANT SELECT ON model TO infinispan;&lt;/pre&gt; &lt;p&gt;We can now deploy PostgreSQL in OpenShift using the modified image:&lt;/p&gt; &lt;pre&gt; $ oc new-project infinispan-demo $ oc new-build \ &gt; https://github.com/torbjorndahlen/infinispan-evict-cache \ &gt; --strategy=docker \ &gt; --name='postgresql-12-custom' $ oc new-app \ &gt; -e POSTGRESQL_USER=db \ &gt; -e POSTGRESQL_PASSWORD=secret \ &gt; -e POSTGRESQL_DATABASE=rpi-store \ &gt; postgresql-12-custom&lt;/pre&gt; &lt;p&gt;After deployment is complete, we can verify that the user &lt;code&gt;infinispan&lt;/code&gt;, the DB &lt;code&gt;rpi-store&lt;/code&gt;, and the &lt;code&gt;model&lt;/code&gt; table were created as expected:&lt;/p&gt; &lt;pre&gt; $ oc get pods NAME READY STATUS RESTARTS AGE postgresql-12-custom-1-build 0/1 Completed 0 2m40s postgresql-12-custom-0 1/1 Running 0 38s $ oc exec postgresql-12-custom-0 -- psql -U infinispan -d rpi-store -c "select * from model;" id | name | model | soc | memory_mb | ethernet | release_year ----+-------------------+-------+---------+-----------+----------+-------------- 1 | Raspberry Pi | B | BCM2835 | 256 | t | 2012 2 | Raspberry Pi Zero | Zero | BCM2835 | 512 | f | 2015 3 | Raspberry Pi Zero | 2W | BCM2835 | 512 | f | 2021 (3 rows)&lt;/pre&gt; &lt;h2&gt;Server task implementation&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;EvictReloadTask&lt;/code&gt; class implements the &lt;code&gt;org.infinispan.tasks.ServerTask&lt;/code&gt; interface where the &lt;code&gt;call()&lt;/code&gt; method is invoked by Data Grid when called from the Hot Rod client:&lt;/p&gt; &lt;pre&gt; @MetaInfServices(ServerTask.class) public class EvictReloadTask implements ServerTask, java.io.Serializable { private static final ThreadLocal taskContext = new ThreadLocal&lt;&gt;(); @Override public String call() throws Exception { TaskContext ctx = taskContext.get(); AdvancedCache&lt;?, ?&gt; cache = ctx.getCacheManager().getCache("rpi-store").getAdvancedCache(); cache.withFlags(Flag.SKIP_CACHE_STORE).clear(); cache.getComponentRegistry().getComponent(PreloadManager.class).start(); return null; } }&lt;/pre&gt; &lt;p&gt;Before deploying Data Grid, the server task is packaged in a JAR file containing the server task classes and a file in the &lt;code&gt;META-INF/services&lt;/code&gt; directory. This file is named &lt;code&gt;org.infinispan.tasks.ServerTask&lt;/code&gt; and contains the fully qualified name of the server task.&lt;/p&gt; &lt;pre&gt; example.EvictReloadTask&lt;/pre&gt; &lt;p&gt;You also need to add your server task classes to a deserialization allow list, since Data Grid does not allow deserialization of arbitrary Java classes for security reasons. To do this, we create a ConfigMap containing an allow-list for serializing of the server task class:&lt;/p&gt; &lt;pre&gt; apiVersion: v1 kind: ConfigMap metadata: name: cluster-config namespace: infinispan-demo data: infinispan-config.xml: &gt; &lt;infinispan&gt; &lt;cache-container&gt; &lt;serialization marshaller="org.infinispan.commons.marshall.JavaSerializationMarshaller"&gt; &lt;allow-list&gt; &lt;class&gt;example.EvictReloadTask&lt;/class&gt; &lt;/allow-list&gt; &lt;/serialization&gt; &lt;/cache-container&gt; &lt;/infinispan&gt;&lt;/pre&gt; &lt;p&gt;Then, we deploy the ConfigMap:&lt;/p&gt; &lt;pre&gt; $ oc apply -f cluster-config.yaml&lt;/pre&gt; &lt;h2&gt;Deploy Data Grid&lt;/h2&gt; &lt;p&gt;To deploy the Data Grid cluster in OpenShift we use the Data Grid operator.&lt;/p&gt; &lt;p&gt;Install the operator:&lt;/p&gt; &lt;pre&gt; $ oc apply -f infinispan-operator.yaml $ oc apply -f subscription.yaml&lt;/pre&gt; &lt;p&gt;In this example, we will use the following custom resource to let the operator create a Data Grid cluster:&lt;/p&gt; &lt;pre&gt; apiVersion: infinispan.org/v1 kind: Infinispan metadata: name: infinispan namespace: infinispan-demo spec: security: endpointEncryption: type: None clientCert: None expose: type: LoadBalancer dependencies: artifacts: - maven: 'org.postgresql:postgresql:42.3.1' - url: &gt;- https://github.com/torbjorndahlen/infinispan-evict-cache/raw/main/ServerTask/server/target/ServerTask.jar service: type: DataGrid replicas: 1 configMapName: cluster-config&lt;/pre&gt; &lt;p&gt;The Maven artifact refers to the JDBC driver for PostgreSQL. The URL artifact refers to the Git repository where the server task JAR file can be downloaded.&lt;/p&gt; &lt;p&gt;The Data Grid cluster is created with oc create:&lt;/p&gt; &lt;pre&gt; $ oc create -f infinispan-cr.yaml&lt;/pre&gt; &lt;p&gt;Use &lt;code&gt;oc get svc&lt;/code&gt; to find the URL to the Data Grid console:&lt;/p&gt; &lt;pre&gt; $ oc get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE example-infinispan-external LoadBalancer 172.30.5.74 my_host.example.com 11222:31797/TCP 6m39s&lt;/pre&gt; &lt;p&gt;In this example, we exposed Data Grid through a loadbalancer. The URL to the Data Grid contains the loadbalancer hostname and port. The Data Grid console can be accessed at &lt;code&gt;http://my_host.example.com:11222&lt;/code&gt;. The console username and password is stored in the &lt;code&gt;infinispan-generated-secret&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt; $ oc get secret infinispan-generated-secret -o jsonpath="{.data.identities\.yaml}" | base64 --decode credentials: - username: developer password: my_password roles: - admin&lt;/pre&gt; &lt;h2&gt;Create the cache&lt;/h2&gt; &lt;p&gt;You can use SQL stores with database tables that contain composite primary keys or composite values.&lt;/p&gt; &lt;p&gt;To use composite keys or values, you must provide Data Grid with protobuf schema that describe the data types. You must also add schema configuration to your SQL store and specify the message names for keys and values.&lt;/p&gt; &lt;p&gt;You can find more information on &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.4/html-single/cache_encoding_and_marshalling/index#doc-wrapper"&gt;cache encoding and marshaling&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Using the Data Grid console, create a cache using a protobuf schema and SQL cache store configuration, as shown in Figure 1:&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/skarmavbild_2023-04-20_kl._12.38.50.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/skarmavbild_2023-04-20_kl._12.38.50.png?itok=Xd9U3r3w" width="600" height="452" alt="A screenshot of the Data Grid console, creating a cache using a protobuf schema." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: Creating a cache using a protobuf schema in the Data Grid console.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Use the following configuration for the cache. In the configuration, &lt;code&gt;table-name&lt;/code&gt; refers to the &lt;code&gt;model&lt;/code&gt; table created when PostgreSQL was deployed. The &lt;code&gt;message-name&lt;/code&gt; and &lt;code&gt;package&lt;/code&gt; refers to the protobuf schema. Notice the user &lt;code&gt;infinispan&lt;/code&gt; that was previously created is used by the JDBC driver.&lt;/p&gt; &lt;pre&gt; { "distributed-cache": { "mode": "SYNC", "encoding": { "key": { "media-type": "application/x-protostream" }, "value": { "media-type": "application/x-protostream" } }, "persistence": { "table-jdbc-store": { "shared": true, "segmented": false, "dialect": "POSTGRES", "table-name": "model", "schema": { "message-name": "model_value", "package": "example" }, "connection-pool": { "connection-url": "jdbc:postgresql://postgresql-12-custom:5432/rpi-store", "driver": "org.postgresql.Driver", "username": "infinispan", "password": "secret" } } } } }&lt;/pre&gt; &lt;p&gt;When created, the cache will automatically load the &lt;code&gt;model&lt;/code&gt; table, as shown in Figure 2:&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/skarmavbild_2023-04-20_kl._12.52.01.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/skarmavbild_2023-04-20_kl._12.52.01.png?itok=0NTHk2Jh" width="600" height="489" alt="Shows the cache with entries from the model table." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: The cache is loaded with entries from the model table.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Run the server task&lt;/h2&gt; &lt;p&gt;In our example, the table from which Data Grid loaded the entries to the cache will be modified without notifying Data Grid. To update the cache with the modified entry, the server task will be called from a Hot Rod client.&lt;/p&gt; &lt;p&gt;First, we update a row in the model table:&lt;/p&gt; &lt;pre&gt; $ oc exec postgresql-12-custom-0 -- psql -U postgres -d rpi-store -c "update model set name = 'Raspberry Pi UPDATED' where id = 1;" $ oc exec postgresql-12-custom-0 -- psql -U infinispan -d rpi-store -c "select * from model;" id | name | model | soc | memory_mb | ethernet | release_year ----+-----------------------+-------+---------+-----------+----------+-------------- 2 | Raspberry Pi Zero | Zero | BCM2835 | 512 | f | 2015 3 | Raspberry Pi Zero | 2W | BCM2835 | 512 | f | 2021 1 | Raspberry Pi UPDATED | B | BCM2835 | 256 | t | 2012 (3 rows)&lt;/pre&gt; &lt;p&gt;Verify that the cache doesn't contain the updated entry by using the Infinispan CLI to lookup the key 1 in the cache:&lt;/p&gt; &lt;pre&gt; $ oc get pods NAME READY STATUS RESTARTS AGE infinispan-0 1/1 Running 0 86s $ oc rsh infinispan-0 sh-4.4$./bin/cli.sh [disconnected]&gt; connect Username: developer Password: my_password [infinispan-0-28040@infinispan//containers/default]&gt; cd caches [infinispan-0-28040@infinispan//containers/default/caches]&gt; cd rpi-store [infinispan-0-28040@infinispan//containers/default/caches/rpi-store]&gt; get 1 { "_type" : "example.model_value", "name" : "Raspberry Pi", "model" : "B", "soc" : "BCM2835", "memory_mb" : 256, "ethernet" : true, "release_year" : 2012 }&lt;/pre&gt; &lt;p&gt;The cache hasn't been notified about the modified row and still contains the name, &lt;strong&gt;Raspberry Pi&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;To load the modified entry into the cache, we run the client. The username and password are located under &lt;strong&gt;Secrets&lt;/strong&gt; in &lt;code&gt;infinispan-generated-secret&lt;/code&gt;.&lt;strong&gt; &lt;/strong&gt;The Data Grid server can be accessed from the infinispan loadbalancer hostname and port.&lt;/p&gt; &lt;pre&gt; $ git clone https://github.com/torbjorndahlen/infinispan-evict-cache.git $ cd infinispan-evict-cache/ServerTask/client $ mvn clean package $ mvn assembly:assembly -DdescriptorId=jar-with-dependencies $ java -cp target/ServerTaskClient-jar-with-dependencies.jar \ &gt; example.CacheServerTaskInvocation \ &gt; my_host.example.com 11222 \ &gt; developer my_password rpi-store&lt;/pre&gt; &lt;p&gt;Verify that the cache now contains the modified entries by using the Infinispan CLI to lookup the key 1 in the cache:&lt;/p&gt; &lt;pre&gt; $ oc rsh infinispan-0 sh-4.4$./bin/cli.sh [disconnected]&gt; connect Username: developer Password: my_password [infinispan-0-28040@infinispan//containers/default]&gt; cd caches [infinispan-0-28040@infinispan//containers/default/caches]&gt; cd rpi-store [infinispan-0-28040@infinispan//containers/default/caches/rpi-store]&gt; get 1 { "_type" : "example.model_value", "name" : "Raspberry Pi UPDATED", "model" : "B", "soc" : "BCM2835", "memory_mb" : 256, "ethernet" : true, "release_year" : 2012 }&lt;/pre&gt; &lt;p&gt;The updated value for &lt;strong&gt;key 1&lt;/strong&gt; has been loaded into the cache.&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;In this article, we demonstrated how a cache using a PostgreSQL database as a cache store can be refreshed by using a server task invoked from a Hot Rod client when a table is being updated by other means than passing through Data Grid.&lt;/p&gt; &lt;p&gt;Thanks to Tristan Tarrant at Red Hat for providing advice and suggestions on the implementation of this tutorial.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/18/how-run-custom-server-task-red-hat-data-grid" title="How to run a custom server task in Red Hat Data Grid"&gt;How to run a custom server task in Red Hat Data Grid&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Torbjorn Dahlen</dc:creator><dc:date>2023-07-18T07:00:00Z</dc:date></entry><entry><title type="html">Keycloak 22.0.1 released</title><link rel="alternate" href="https://www.keycloak.org/2023/07/keycloak-2201-released" /><author><name /></author><id>https://www.keycloak.org/2023/07/keycloak-2201-released</id><updated>2023-07-18T00:00:00Z</updated><content type="html">To download the release go to . MIGRATION FROM 21.1 Before you upgrade remember to backup your database. If you are not on the previous release refer to for a complete list of migration changes. ALL RESOLVED ISSUES ENHANCEMENTS * Revisit Pod-Template in Keycloak CR keycloak operator * Support configurable custom Identity Providers keycloak * [REG 21-&gt;22] Error messages on kc build keycloak dist/quarkus BUGS * Accessibility/Clients List: Minor Issues keycloak admin/ui * `keycloakCRName` and `realm` are no longer marked as required in KeycloakRealmImport CRD keycloak operator * Version 22.0.0 not started in dev mode and build mode keycloak dist/quarkus * Migration for 22.0.0 is missing from the documentation keycloak docs * Broken links to quickstarts in documentation keycloak docs * Account V3 Missing translate Refresh keycloak account/ui * Keycloak is storing error events even if storing events is disabled keycloak storage * Fixing broken JSON translation files keycloak admin/ui UPGRADING Before you upgrade remember to backup your database and check the for anything that may have changed.</content><dc:creator /></entry><entry><title type="html">How to run standalone Jakarta Batch Jobs</title><link rel="alternate" href="https://www.mastertheboss.com/java-ee/batch-api/running-batch-jobs-in-j2se-applications/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/java-ee/batch-api/running-batch-jobs-in-j2se-applications/</id><updated>2023-07-14T10:16:48Z</updated><content type="html">Jakarta Batch, formerly known as Java Batch, is a specification that provides a standardized approach for implementing batch processing in Java applications. It offers a robust and scalable framework for executing large-scale, long-running, and data-intensive tasks. In this tutorial, we will explore the process of running Jakarta Batch Jobs as standalone Java applications, discussing the ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>A developer’s path to success with OpenShift and containers</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/13/developers-path-success-openshift-and-containers" /><author><name>Valentina Rodriguez Sosa</name></author><id>e01ea10c-6333-49c0-8681-48b4641c4ebe</id><updated>2023-07-13T07:00:00Z</updated><published>2023-07-13T07:00:00Z</published><summary type="html">&lt;p&gt;I am a developer new to containers, Kubernetes, or CI/CD. Where should I start?&lt;/p&gt; &lt;p&gt;This article provides five pathways including resources to succeed on your container journey.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Highlighted material:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;The following materials are free with no prerequisites.&lt;/li&gt; &lt;li aria-level="1"&gt;These materials are foundational for you to start working on your next project ASAP.&lt;/li&gt; &lt;li aria-level="1"&gt;Training materials will take up to five hours to complete.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;1. Start building your skills with containers and OpenShift&lt;/h2&gt; &lt;p&gt;To start with containers, understand what containers are and how CI/CD can automate the software development lifecycle. &lt;/p&gt; &lt;ul&gt;&lt;li aria-level="2"&gt;Documentation: &lt;a href="https://www.redhat.com/en/topics/containers#overview"&gt;Understanding containers &lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;Blog: &lt;a href="https://developers.redhat.com/blog/2020/09/03/the-present-and-future-of-ci-cd-with-gitops-on-red-hat-openshift#"&gt;The present and future of CI/CD with GitOps on Red Hat OpenShift &lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;Documentation: &lt;a href="https://www.redhat.com/en/topics/cloud-native-apps"&gt;Understanding Cloud Native Applications&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Start building your skills&lt;/h3&gt; &lt;p&gt;Gather hands-on experience with video tutorials and learning paths to practice the concepts learned from foundational to advanced on OpenShift.&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="2"&gt;Video tutorial: &lt;a href="https://developers.redhat.com/learn/openshift/foundations-openshift"&gt;Foundations of OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;Video tutorial: &lt;a href="https://developers.redhat.com/learn/openshift"&gt;OpenShift and Kubernetes learning&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;Try the Developer Sandbox for Red Hat OpenShift: &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Start exploring in the Developer Sandbox for free&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Learn more about Kubernetes&lt;/h3&gt; &lt;p&gt;A deep dive on Kubernetes concepts from services to containers and pods: &lt;/p&gt; &lt;ul&gt;&lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2023/04/05/kubernetes-patterns-path-cloud-native"&gt;Kubernetes Patterns: The path to cloud native&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Our product documentation&lt;/h3&gt; &lt;p&gt;Discover all the features and capabilities of OpenShift from our product documentation.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/openshift_images/index.html"&gt;Overview of Images in Red Hat OpenShift &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/applications/index.html"&gt;Building Applications with Red Hat OpenShift &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/web_console/web-console-overview.html"&gt;OpenShift Web Console Overview&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;2. Modernize your applications&lt;/h2&gt; &lt;p&gt;Explore the practices to move your application to containers.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Video tutorial and additional materials: &lt;a href="https://developers.redhat.com/topics/microservices"&gt;Developing microservices on Kubernetes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/topics/application-modernization/what-is-dotnet-modernization#:~:text=The%20purpose%20of%20workload%20modernization,and%20integrating%20old%20with%20new."&gt;What is .NET application modernization?&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2023/05/15/how-use-new-openshift-quick-starts-deploy-jboss-eap"&gt;OpenShift QuickStarts to deploy JBossEAP&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Ready to practice?&lt;/h3&gt; &lt;p&gt;Practice the concepts learn with our Developer Sandbox for Red Hat OpenShift, tutorials, and hands-on labs.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Tutorials: &lt;a href="https://developers.redhat.com/topics"&gt;All Development topics with Red Hat Developer &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Video tutorial: &lt;a href="https://www.redhat.com/en/services/training/do092-developing-cloud-native-applications-microservices-architectures"&gt;Developing cloud-native applications with microservices&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Hands-on lab: &lt;a href="https://developers.redhat.com/learn/openshift/develop-on-openshift"&gt;Developing on OpenShift&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Learn more about application development&lt;/h3&gt; &lt;p&gt;Learn about Red Hat Enterprise Linux capabilities to improve the developer experience and container applications development experience.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2023/05/10/how-new-rhel-92-improves-developer-experience#"&gt;How the new RHEL 9.2 improves the developer experience &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2022/12/12/kubernetes-native-inner-loop-development-quarkus"&gt;Kubernetes-native inner loop development with Quarkus&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;3. Migrate at scale with OpenShift&lt;/h2&gt; &lt;p&gt;After migrating a couple of applications, you might wonder how we can replicate this process across an organization. Discover where to start with the modernization journey and how the developer experience can be improved.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Demo video: &lt;a href="https://www.youtube.com/watch?v=Pe0bFA4WawQ"&gt;Build, test, tune, and deploy your application with Red Hat OpenShift Dev Spaces&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2023/05/23/podman-desktop-now-generally-available"&gt;Podman Desktop 1.0: Local container development made easy &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://docs.openshift.com/container-platform/4.13/applications/odc-viewing-application-composition-using-topology-view.html"&gt;Viewing application composition using the Topology view &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/topics/application-modernization"&gt;Modernizing existing applications&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Ready to try?&lt;/h3&gt; &lt;p&gt;Start analyzing and assessing applications with MTA. Learn from our demo and product documentation.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=u9N-T-uD_KU"&gt;Migration Toolkit For Applications&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Learn more about migration&lt;/h3&gt; &lt;p&gt;Plan your Java application modernization journey with our e-book and learn Podman's capabilities.&lt;/p&gt; &lt;ul&gt;&lt;li class="Indent1"&gt;Article: &lt;a href="https://developers.redhat.com/articles/2022/05/02/podman-basics-resources-beginners-and-experts#"&gt;Podman basics &lt;/a&gt;&lt;/li&gt; &lt;li class="Indent1"&gt;E-book: &lt;a href="https://www.redhat.com/en/engage/java-application-modernization-20220926"&gt;A practical guide to kick-start your own initiative&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;4. Automate to accelerate your software development lifecycle&lt;/h2&gt; &lt;p&gt;Automate software development process adopting GitOps approach and secure with DevSecOps.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2022/09/07/how-set-your-gitops-directory-structure"&gt;How to set up your GitOps directory structure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2022/07/20/git-workflows-best-practices-gitops-deployments"&gt;Git best practices: Workflows for GitOps deployments&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/topics/devops/what-is-devsecops"&gt;What's DevSecOps &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation and demos: &lt;a href="https://developers.redhat.com/topics/devsecops"&gt;DevSecOps: Automating security in the development lifecycle&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Ready to try automation?&lt;/h3&gt; &lt;p&gt;Learn from these free hands-on labs how to bring automation with CI/CD and GitOps practices by using Helm, OpenShift Pipelines, Jenkins, Ansible Automation Platform, and OpenShift GitOps.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/learn/openshift/develop-gitops"&gt;Develop with GitOps &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/courses/gitops/getting-started-openshift-pipelines"&gt;Getting Started with OpenShift Pipelines&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/courses/cicd-ansible-automation-platform-and-jenkins-openshift"&gt;CI/CD with the Ansible Automation Platform and Jenkins on OpenShift &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/courses/gitops/working-helm"&gt;Working with Helm&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Learn more about DevOps&lt;/h3&gt; &lt;p&gt;These e-books will help you start with best practices and practical guides to transform into a DevOps culture.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/e-books/path-gitops"&gt;The Path to GitOps &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/engage/devops-culture-practice-openshift-ebooks"&gt;DevOps Culture and Practice with OpenShift&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Our product documentation&lt;/h3&gt; &lt;p&gt;Review our product documentation to learn about features and much more.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/cicd/index.html"&gt;OpenShift CI/CD &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/applications/working_with_helm_charts/understanding-helm.html"&gt;Understanding Helm &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/cicd/gitops/understanding-openshift-gitops.html"&gt;Understanding OpenShift GitOps&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;5. How to innovate with OpenShift&lt;/h2&gt; &lt;p&gt;Learn about key OpenShift capabilities to bring innovation to applications from serverless architectures, interconnecting services in diverse platforms, and securing and observing microservices with OpenShift Service Mesh.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/serverless"&gt;What's Red Hat OpenShift &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/serverless"&gt;Serverless&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://developers.redhat.com/products/service-interconnect/overview"&gt;Interconnect applications and microservices across the open hybrid cloud&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Tutorials, books, videos and more: &lt;a href="https://developers.redhat.com/topics/serverless-architecture#assembly-field-sections-38375"&gt;Build serverless architectures for Kubernetes with Knative &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/what-is-openshift-service-mesh"&gt;What's Red Hat OpenShift Service Mesh&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Ready to try OpenShift components?&lt;/h3&gt; &lt;p&gt;Gather hands-on experience with our free labs and follow tutorials and demos at your own pace.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Hands-on lab: &lt;a href="https://developers.redhat.com/courses/getting-started-openshift-serverless"&gt;Getting Started with OpenShift Serverless &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Demo: &lt;a href="https://www.youtube.com/watch?v=YoGR5zZGG9k"&gt;OpenShift Service Mesh&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Learn more about OpenShift Service Mesh&lt;/h3&gt; &lt;p&gt;This e-book provides guidance on governance, design practices, and configuring Red Hat OpenShift Service Mesh for production use and performing day-2 operations. &lt;/p&gt; &lt;ul&gt;&lt;li&gt;E-book: &lt;a href="https://www.redhat.com/en/resources/getting-started-with-openshift-service-mesh-ebook"&gt;Getting Started with Red Hat OpenShift Service Mesh&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Find more resources in our product documentation&lt;/h3&gt; &lt;p&gt;Learn about product capabilities, features, and much more from our product documentation.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/service_mesh/v2x/ossm-about.html"&gt;OpenShift Service Mesh &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/serverless/about/about-serverless.html"&gt;OpenShift Serverless &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/distr_tracing/distributed-tracing-release-notes.html"&gt;Distributed Tracing&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/13/developers-path-success-openshift-and-containers" title="A developer’s path to success with OpenShift and containers"&gt;A developer’s path to success with OpenShift and containers&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Valentina Rodriguez Sosa</dc:creator><dc:date>2023-07-13T07:00:00Z</dc:date></entry><entry><title>Quarkus Newsletter #34 - July</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-newsletter-34/&#xA;            " /><author><name>James Cobb (https://twitter.com/insectengine)</name></author><id>https://quarkus.io/blog/quarkus-newsletter-34/</id><updated>2023-07-13T00:00:00Z</updated><published>2023-07-13T00:00:00Z</published><summary type="html">Read "Quarkus 3.2.0.Final released - New security features, @QuarkusComponentTest" by Guillaume Smet" to learn about major changes like; various new security features, the ability to test CDI components with @QuarkusComponentTest and new build time analytics. Kevin Dubois' article "Managing Java containers with Quarkus and Podman Desktop" shows how to build...</summary><dc:creator>James Cobb (https://twitter.com/insectengine)</dc:creator><dc:date>2023-07-13T00:00:00Z</dc:date></entry></feed>
